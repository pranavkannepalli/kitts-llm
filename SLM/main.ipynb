{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Embedding,\n",
    "    Dense,\n",
    "    LSTM,\n",
    "    Input,\n",
    "    GlobalAveragePooling1D,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    "    LayerNormalization,\n",
    "    MultiHeadAttention,\n",
    "    Add\n",
    ")\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built with CUDA: False\n"
     ]
    }
   ],
   "source": [
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 128\n",
    "stride = 1\n",
    "embedding_dim = 512\n",
    "num_layers = 16\n",
    "num_heads = 8\n",
    "ff_dim = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I remember the first time I grasped the power of natural language processing (NLP). In 9th grade, I was toying around with Google Translate when I began wondering how it works. To an end user, it might look simple—type in a sentence, hit enter, and voilà, the machine gives you a translation for any of its 234 languages. I couldn\\'t help but think, How is this even possible? Language is so messy and full of nuances.\\nThis fascination resonated with my love for math—I find myself searching for numerical patterns, whether factoring street numbers or playing \"24\" with words (where A=1, B=2, and so on). Through NLP, I discovered how computers could transform language into mathematical representations, combining my love of patterns with real-world impact.\\nMy passion grew through hands-on projects. After completing Stanford\\'s NLP course on Coursera, I sought mentorship from Krishna Chintalapudi, a Principal Researcher at Microsoft, to improve text classification techniques. For Technology Student Association competitions, I integrated NLP into real-world applications, including a sustainable initiatives website with AI-powered suggestions for homeowners. I also developed an app that helps students find college and internship matches using ChatGPT to generate personalized lessons and tasks.\\nBut what truly cemented my decision to major in Computer Science was discovering NLP\\'s limitations: while over 8,000 languages exist worldwide, these tools support only a small fraction. Through my work with language models, I\\'ve seen how computer science can transform communication, but this transformation remains inaccessible to many communities, particularly those speaking low-resource languages. \\nThus, I plan to use my Computer Science education to found a startup extending NLP capabilities to low-resource languages, making digital communication tools truly inclusive. For me, CS isn\\'t just a major—it\\'s a path to ensuring no community gets left behind in our digital future.',\n",
       " 'Math was my first love, enthralling me with its evolving nature and pushing me to think critically. This passion led to Computer Science, where I discovered a similar thrill, with the added benefit of creating solutions that impact people’s lives. While working for a nonprofit in India, I built a website for low-income women to sell their products. I had to quickly learn how to set up Google Cloud service accounts, create translation layers for accessibility, and develop a backend using Google Sheets as a database, ensuring it was user-friendly for a team with no coding experience. Acquiring these new skills, though challenging, was worth it when I witnessed the website reaching a broader audience and allowing these women to gain financial independence. It also gave me a clear understanding of how I want to use technology in the future—to empower people and create lasting change.\\nCraving a deeper understanding, I pursued research under a Principal Researcher at Microsoft, exploring NLP classification techniques using LLMs. This forced me to think beyond code, diving into the training mechanisms and optimizations behind these models. Being exposed to the depth of CS, I realized how much there remains to learn about the technology behind the solutions I create.\\nI further honed my skills during an internship at Applied Systems, where I worked as the only high schooler on their AI engineering team and took on the responsibilities of a full software engineer. I was entrusted with building a test playground in React to help clients evaluate their services. To achieve this, I worked with production APIs and deployment manifests, written in languages I knew little about. I turned to my colleagues for support, who guided me with the fundamentals of Go and Kubernetes. Each new challenge reinforced that coding is about constant learning and adaptation—skills I’ve embraced from the start.\\nAt CMU, I will continue pushing the boundaries of what I can create.',\n",
       " \"For me, a successful college experience means acquiring the skills and knowledge to make meaningful contributions to the field of AI while creating impactful solutions for underrepresented communities. Carnegie Mellon University’s rigorous academic environment and focus on innovation make it the ideal place to realize this vision.\\nCMU’s robust computer science program excites me, especially courses like 11-711: Algorithms for NLP and 11-744: Question Answering and Dialogue Systems, which align with my passion for low-resource language processing. These courses will help me build upon my high school NLP research and internship experiences, where I developed classification techniques for LLMs. At CMU, I aspire to expand these efforts by working with faculty like Professor Graham Neubig, whose research on multilingual NLP and transfer learning for low-resource languages aligns with my goal of bridging language barriers. His work inspires me to explore how NLP can empower communities worldwide, whether through improved translation systems or accessible AI tools.\\nBeyond coursework, CMU’s focus on interdisciplinary collaboration is deeply appealing. The Language Technologies Institute and its emphasis on both theoretical and applied AI will provide me with opportunities to engage in cutting-edge research. I’m particularly drawn to the CMU AI Mentorship Program, where I can collaborate with peers and mentors on impactful projects. This will prepare me for my ultimate goal of founding an AI startup focused on low-resource languages, leveraging CMU's Swartz Center for Entrepreneurship for guidance and resources.\\nA successful college experience is also about balance and personal growth. CMU’s vibrant cricket culture offers the perfect outlet for me to stay active and connect with fellow students. Competing with international peers will remind me of the resilience and teamwork I’ve cultivated through years of playing cricket. At CMU, I hope to merge technical excellence with personal fulfillment, equipping myself to leave a lasting impact on the world.\",\n",
       " \"I come from a community rooted in STEM, where learning and teaching go hand in hand. As a student, I've challenged myself through advanced courses, national-level math competitions, and self-studying coding languages, preparing me for internships and real-world applications. But my passion extends beyond personal growth; I'm committed to sharing knowledge with those who lack equal access, which inspired me to found the Kirkland chapter of Steel City Codes (SCC), offering free coding lessons to underrepresented kids.\\nInitially, my lessons didn't resonate – I was wrongly assuming students had prior tech knowledge. After recognizing this oversight, I revamped the curriculum with interactive elements and trained volunteers to adapt lessons for varying skill levels. Starting with simple analogies for beginners, like explaining variables as boxes holding information, while offering challenge problems for advanced students, we saw transformative results. One student, Tommaso, went from reluctant participant to eager learner, while Mateo progressed from struggling with basic commands to developing his own text-based adventure game. Their journey from confusion to enthusiasm became my most rewarding experience.\\nAt CMU, I'm especially excited to contribute to CMU CS Academy, a platform I've experienced firsthand as a student. Having benefited from its well-structured Python curriculum, I'm eager to help enhance and develop new content that can reach even more students nationwide. Through the Leonard Gelfand Center's K-12 outreach initiatives, I plan to create additional support systems for schools adopting CS Academy, drawing from my experience with both sides of the platform to make computer science education more accessible and engaging.\\nAdditionally, I hope to work with CMU's Computer Science Pathways program, which connects local high school students with undergraduate mentors. By sharing my experiences and knowledge, I can help inspire the next generation of Pittsburgh's tech innovators while contributing to CMU's mission of fostering inclusive technical education in our community.\",\n",
       " 'As much as I’m a student, I’m also a teacher. This belief inspired me to found the Kirkland chapter of Steel City Codes (SCC) to teach coding to underrepresented children. \\nWith SCC, I developed a curriculum that emphasizes hands-on learning through engaging projects and designed workshops that introduce fundamental programming concepts, allowing students to create their own applications and games. By fostering an interactive learning environment, I encouraged creativity and critical thinking while making coding accessible to all participants. Moreover, I collaborated with local schools and community organizations to reach a diverse range of students, ensuring that everyone has the opportunity to explore the tech field.\\nTeaching has not only enabled me to share my knowledge but has also deepened my understanding. I’m eager to continue this work at Columbia through programs like Sci-Inspire and Columbia University Competitions in Math, mentoring young learners and making STEM more inclusive.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_essays_from_folder(folder_path):\n",
    "    essays = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(folder_path, filename), 'r', encoding='utf-8') as f:\n",
    "                essays.append(f.read())\n",
    "    return essays \n",
    "\n",
    "essays = load_essays_from_folder('rawdata/essays')\n",
    "essays[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(essays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2273"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sliding_window_data(sequence):\n",
    "    inputs = []\n",
    "    labels = []\n",
    "\n",
    "    for i in range(0, len(sequence) - window_size, stride):\n",
    "        window_sequence = sequence[i:i + window_size]\n",
    "        next_tokens = sequence[i + 1:i + window_size + 1]  # Shift by one for labels\n",
    "        inputs.append(window_sequence)\n",
    "        labels.append(next_tokens)\n",
    "\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(essays):\n",
    "    inputs = []\n",
    "    labels = []\n",
    "\n",
    "    for essay in essays:\n",
    "        tokenized_essay = tokenizer.texts_to_sequences([essay])[0]\n",
    "        essay_inputs, essay_labels = generate_sliding_window_data(tokenized_essay)\n",
    "        inputs.extend(essay_inputs)\n",
    "        labels.extend(essay_labels)\n",
    "\n",
    "    return np.array(inputs), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels= prepare_data(essays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_tensor_slices((inputs, labels))\n",
    "train_dataset = train_dataset.shuffle(10000).batch(8).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(8, 128), dtype=int32, numpy=\n",
      "array([[   7,   14,   45, ...,  144,    3,  532],\n",
      "       [ 671,    9, 2227, ...,   13,   23,  109],\n",
      "       [ 217, 1440,   10, ...,    7, 1467,  997],\n",
      "       ...,\n",
      "       [ 413,   24,  229, ...,   14,  128,    8],\n",
      "       [1516,   20,  476, ...,  142, 1539,  202],\n",
      "       [ 625,  482,   11, ...,    5, 1691,    1]])>, <tf.Tensor: shape=(8, 128), dtype=int32, numpy=\n",
      "array([[  14,   45,  885, ...,    3,  532,    7],\n",
      "       [   9, 2227,    1, ...,   23,  109,   71],\n",
      "       [1440,   10,    5, ..., 1467,  997,  789],\n",
      "       ...,\n",
      "       [  24,  229,    4, ...,  128,    8,    6],\n",
      "       [  20,  476,  805, ..., 1539,  202,  478],\n",
      "       [ 482,   11,    4, ..., 1691,    1,  371]])>)\n",
      "Input shape: (8, 128)\n",
      "Label shape: (8, 128)\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataset.take(1):\n",
    "    print(batch)\n",
    "    input_shape = batch[0].shape\n",
    "    label_shape = batch[1].shape\n",
    "    print(f'Input shape: {input_shape}')\n",
    "    print(f'Label shape: {label_shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(window_size,))\n",
    "embedding = Embedding(vocab_size, embedding_dim)(inputs) \n",
    "positional_encoding = Embedding(input_dim=window_size, output_dim=embedding_dim)(tf.range(start=0, limit=window_size))\n",
    "positional_encoding = tf.expand_dims(positional_encoding, 0)\n",
    "embedding = Add()([embedding, positional_encoding])\n",
    "\n",
    "x = embedding\n",
    "\n",
    "for _ in range(num_layers):\n",
    "    attn = MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim // num_heads)(x, x)\n",
    "    x = Add()([x, attn])\n",
    "    x = LayerNormalization()(x)\n",
    "\n",
    "    ff = Dense(ff_dim, activation='relu')(x)\n",
    "    ff = Dense(embedding_dim)(ff)\n",
    "    x = Add()([x, ff])\n",
    "    x = LayerNormalization()(x)\n",
    "\n",
    "outputs = Dense(vocab_size, activation='softmax')(x)\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 128)]                0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 128, 512)             1163776   ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 128, 512)             0         ['embedding[0][0]']           \n",
      "                                                                                                  \n",
      " multi_head_attention (Mult  (None, 128, 512)             1050624   ['add[0][0]',                 \n",
      " iHeadAttention)                                                     'add[0][0]']                 \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 128, 512)             0         ['add[0][0]',                 \n",
      "                                                                     'multi_head_attention[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization (Layer  (None, 128, 512)             1024      ['add_1[0][0]']               \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 128, 1024)            525312    ['layer_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 128, 512)             524800    ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " add_2 (Add)                 (None, 128, 512)             0         ['layer_normalization[0][0]', \n",
      "                                                                     'dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_1 (Lay  (None, 128, 512)             1024      ['add_2[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (Mu  (None, 128, 512)             1050624   ['layer_normalization_1[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_3 (Add)                 (None, 128, 512)             0         ['layer_normalization_1[0][0]'\n",
      "                                                                    , 'multi_head_attention_1[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " layer_normalization_2 (Lay  (None, 128, 512)             1024      ['add_3[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 128, 1024)            525312    ['layer_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 128, 512)             524800    ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " add_4 (Add)                 (None, 128, 512)             0         ['layer_normalization_2[0][0]'\n",
      "                                                                    , 'dense_3[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_3 (Lay  (None, 128, 512)             1024      ['add_4[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (Mu  (None, 128, 512)             1050624   ['layer_normalization_3[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_3[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_5 (Add)                 (None, 128, 512)             0         ['layer_normalization_3[0][0]'\n",
      "                                                                    , 'multi_head_attention_2[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " layer_normalization_4 (Lay  (None, 128, 512)             1024      ['add_5[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 128, 1024)            525312    ['layer_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 128, 512)             524800    ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      " add_6 (Add)                 (None, 128, 512)             0         ['layer_normalization_4[0][0]'\n",
      "                                                                    , 'dense_5[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_5 (Lay  (None, 128, 512)             1024      ['add_6[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (Mu  (None, 128, 512)             1050624   ['layer_normalization_5[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_5[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_7 (Add)                 (None, 128, 512)             0         ['layer_normalization_5[0][0]'\n",
      "                                                                    , 'multi_head_attention_3[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " layer_normalization_6 (Lay  (None, 128, 512)             1024      ['add_7[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 128, 1024)            525312    ['layer_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 128, 512)             524800    ['dense_6[0][0]']             \n",
      "                                                                                                  \n",
      " add_8 (Add)                 (None, 128, 512)             0         ['layer_normalization_6[0][0]'\n",
      "                                                                    , 'dense_7[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_7 (Lay  (None, 128, 512)             1024      ['add_8[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " multi_head_attention_4 (Mu  (None, 128, 512)             1050624   ['layer_normalization_7[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_7[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_9 (Add)                 (None, 128, 512)             0         ['layer_normalization_7[0][0]'\n",
      "                                                                    , 'multi_head_attention_4[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " layer_normalization_8 (Lay  (None, 128, 512)             1024      ['add_9[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 128, 1024)            525312    ['layer_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 128, 512)             524800    ['dense_8[0][0]']             \n",
      "                                                                                                  \n",
      " add_10 (Add)                (None, 128, 512)             0         ['layer_normalization_8[0][0]'\n",
      "                                                                    , 'dense_9[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_9 (Lay  (None, 128, 512)             1024      ['add_10[0][0]']              \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (Mu  (None, 128, 512)             1050624   ['layer_normalization_9[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_9[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_11 (Add)                (None, 128, 512)             0         ['layer_normalization_9[0][0]'\n",
      "                                                                    , 'multi_head_attention_5[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " layer_normalization_10 (La  (None, 128, 512)             1024      ['add_11[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, 128, 1024)            525312    ['layer_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (None, 128, 512)             524800    ['dense_10[0][0]']            \n",
      "                                                                                                  \n",
      " add_12 (Add)                (None, 128, 512)             0         ['layer_normalization_10[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'dense_11[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_11 (La  (None, 128, 512)             1024      ['add_12[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_6 (Mu  (None, 128, 512)             1050624   ['layer_normalization_11[0][0]\n",
      " ltiHeadAttention)                                                  ',                            \n",
      "                                                                     'layer_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_13 (Add)                (None, 128, 512)             0         ['layer_normalization_11[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'multi_head_attention_6[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_12 (La  (None, 128, 512)             1024      ['add_13[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (None, 128, 1024)            525312    ['layer_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_13 (Dense)            (None, 128, 512)             524800    ['dense_12[0][0]']            \n",
      "                                                                                                  \n",
      " add_14 (Add)                (None, 128, 512)             0         ['layer_normalization_12[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'dense_13[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_13 (La  (None, 128, 512)             1024      ['add_14[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_7 (Mu  (None, 128, 512)             1050624   ['layer_normalization_13[0][0]\n",
      " ltiHeadAttention)                                                  ',                            \n",
      "                                                                     'layer_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_15 (Add)                (None, 128, 512)             0         ['layer_normalization_13[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'multi_head_attention_7[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_14 (La  (None, 128, 512)             1024      ['add_15[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_14 (Dense)            (None, 128, 1024)            525312    ['layer_normalization_14[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_15 (Dense)            (None, 128, 512)             524800    ['dense_14[0][0]']            \n",
      "                                                                                                  \n",
      " add_16 (Add)                (None, 128, 512)             0         ['layer_normalization_14[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'dense_15[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_15 (La  (None, 128, 512)             1024      ['add_16[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_8 (Mu  (None, 128, 512)             1050624   ['layer_normalization_15[0][0]\n",
      " ltiHeadAttention)                                                  ',                            \n",
      "                                                                     'layer_normalization_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_17 (Add)                (None, 128, 512)             0         ['layer_normalization_15[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'multi_head_attention_8[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_16 (La  (None, 128, 512)             1024      ['add_17[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_16 (Dense)            (None, 128, 1024)            525312    ['layer_normalization_16[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_17 (Dense)            (None, 128, 512)             524800    ['dense_16[0][0]']            \n",
      "                                                                                                  \n",
      " add_18 (Add)                (None, 128, 512)             0         ['layer_normalization_16[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'dense_17[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_17 (La  (None, 128, 512)             1024      ['add_18[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_9 (Mu  (None, 128, 512)             1050624   ['layer_normalization_17[0][0]\n",
      " ltiHeadAttention)                                                  ',                            \n",
      "                                                                     'layer_normalization_17[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_19 (Add)                (None, 128, 512)             0         ['layer_normalization_17[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'multi_head_attention_9[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_18 (La  (None, 128, 512)             1024      ['add_19[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_18 (Dense)            (None, 128, 1024)            525312    ['layer_normalization_18[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_19 (Dense)            (None, 128, 512)             524800    ['dense_18[0][0]']            \n",
      "                                                                                                  \n",
      " add_20 (Add)                (None, 128, 512)             0         ['layer_normalization_18[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'dense_19[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_19 (La  (None, 128, 512)             1024      ['add_20[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_10 (M  (None, 128, 512)             1050624   ['layer_normalization_19[0][0]\n",
      " ultiHeadAttention)                                                 ',                            \n",
      "                                                                     'layer_normalization_19[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_21 (Add)                (None, 128, 512)             0         ['layer_normalization_19[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'multi_head_attention_10[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " layer_normalization_20 (La  (None, 128, 512)             1024      ['add_21[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_20 (Dense)            (None, 128, 1024)            525312    ['layer_normalization_20[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_21 (Dense)            (None, 128, 512)             524800    ['dense_20[0][0]']            \n",
      "                                                                                                  \n",
      " add_22 (Add)                (None, 128, 512)             0         ['layer_normalization_20[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'dense_21[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_21 (La  (None, 128, 512)             1024      ['add_22[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_11 (M  (None, 128, 512)             1050624   ['layer_normalization_21[0][0]\n",
      " ultiHeadAttention)                                                 ',                            \n",
      "                                                                     'layer_normalization_21[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_23 (Add)                (None, 128, 512)             0         ['layer_normalization_21[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'multi_head_attention_11[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " layer_normalization_22 (La  (None, 128, 512)             1024      ['add_23[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_22 (Dense)            (None, 128, 1024)            525312    ['layer_normalization_22[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_23 (Dense)            (None, 128, 512)             524800    ['dense_22[0][0]']            \n",
      "                                                                                                  \n",
      " add_24 (Add)                (None, 128, 512)             0         ['layer_normalization_22[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'dense_23[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_23 (La  (None, 128, 512)             1024      ['add_24[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_12 (M  (None, 128, 512)             1050624   ['layer_normalization_23[0][0]\n",
      " ultiHeadAttention)                                                 ',                            \n",
      "                                                                     'layer_normalization_23[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_25 (Add)                (None, 128, 512)             0         ['layer_normalization_23[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'multi_head_attention_12[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " layer_normalization_24 (La  (None, 128, 512)             1024      ['add_25[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_24 (Dense)            (None, 128, 1024)            525312    ['layer_normalization_24[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_25 (Dense)            (None, 128, 512)             524800    ['dense_24[0][0]']            \n",
      "                                                                                                  \n",
      " add_26 (Add)                (None, 128, 512)             0         ['layer_normalization_24[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'dense_25[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_25 (La  (None, 128, 512)             1024      ['add_26[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_13 (M  (None, 128, 512)             1050624   ['layer_normalization_25[0][0]\n",
      " ultiHeadAttention)                                                 ',                            \n",
      "                                                                     'layer_normalization_25[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_27 (Add)                (None, 128, 512)             0         ['layer_normalization_25[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'multi_head_attention_13[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " layer_normalization_26 (La  (None, 128, 512)             1024      ['add_27[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_26 (Dense)            (None, 128, 1024)            525312    ['layer_normalization_26[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_27 (Dense)            (None, 128, 512)             524800    ['dense_26[0][0]']            \n",
      "                                                                                                  \n",
      " add_28 (Add)                (None, 128, 512)             0         ['layer_normalization_26[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'dense_27[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_27 (La  (None, 128, 512)             1024      ['add_28[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_14 (M  (None, 128, 512)             1050624   ['layer_normalization_27[0][0]\n",
      " ultiHeadAttention)                                                 ',                            \n",
      "                                                                     'layer_normalization_27[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_29 (Add)                (None, 128, 512)             0         ['layer_normalization_27[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'multi_head_attention_14[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " layer_normalization_28 (La  (None, 128, 512)             1024      ['add_29[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_28 (Dense)            (None, 128, 1024)            525312    ['layer_normalization_28[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_29 (Dense)            (None, 128, 512)             524800    ['dense_28[0][0]']            \n",
      "                                                                                                  \n",
      " add_30 (Add)                (None, 128, 512)             0         ['layer_normalization_28[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'dense_29[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_29 (La  (None, 128, 512)             1024      ['add_30[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_15 (M  (None, 128, 512)             1050624   ['layer_normalization_29[0][0]\n",
      " ultiHeadAttention)                                                 ',                            \n",
      "                                                                     'layer_normalization_29[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_31 (Add)                (None, 128, 512)             0         ['layer_normalization_29[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'multi_head_attention_15[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " layer_normalization_30 (La  (None, 128, 512)             1024      ['add_31[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_30 (Dense)            (None, 128, 1024)            525312    ['layer_normalization_30[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_31 (Dense)            (None, 128, 512)             524800    ['dense_30[0][0]']            \n",
      "                                                                                                  \n",
      " add_32 (Add)                (None, 128, 512)             0         ['layer_normalization_30[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'dense_31[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_31 (La  (None, 128, 512)             1024      ['add_32[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_32 (Dense)            (None, 128, 2273)            1166049   ['layer_normalization_31[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 35974369 (137.23 MB)\n",
      "Trainable params: 35974369 (137.23 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 17/811 [..............................] - ETA: 15:27 - loss: 6.6843 - accuracy: 0.0317"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kitts\\Documents\\Development\\kittu-llm\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\kitts\\Documents\\Development\\kittu-llm\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\kitts\\Documents\\Development\\kittu-llm\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\kitts\\Documents\\Development\\kittu-llm\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\kitts\\Documents\\Development\\kittu-llm\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\kitts\\Documents\\Development\\kittu-llm\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kitts\\Documents\\Development\\kittu-llm\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\kitts\\Documents\\Development\\kittu-llm\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[1;32mc:\\Users\\kitts\\Documents\\Development\\kittu-llm\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\kitts\\Documents\\Development\\kittu-llm\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
